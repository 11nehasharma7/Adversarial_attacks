# -*- coding: utf-8 -*-
"""Adversarial_attacks_Project.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1XHzlo4Yiy88zN-9RUMj4OYWpP1Je7brq
"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.applications.efficientnet import EfficientNetB0
from tensorflow.keras.applications.efficientnet import preprocess_input as efficientnet_preprocess
from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as mobilenet_preprocess
from tensorflow.keras.applications.resnet import preprocess_input as resnet_preprocess
from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess
from tensorflow.keras.applications.inception_v3 import preprocess_input as inception_preprocess
from tensorflow.keras.applications.densenet import preprocess_input as densenet_preprocess
from tensorflow.keras.applications.xception import preprocess_input as xception_preprocess
from tensorflow.keras.applications.mobilenet_v2 import decode_predictions
import matplotlib.pyplot as plt
import os
from tensorflow.keras.preprocessing import image_dataset_from_directory
from sklearn.metrics import accuracy_score
from keras.applications import (MobileNetV2, ResNet50, ResNet50V2, ResNet101,
                                 ResNet101V2, ResNet152, ResNet152V2,
                                 VGG16, InceptionV3, EfficientNetB0,
                                 DenseNet121, Xception)

# Function to load the selected model and get input shape and preprocess function
def load_model(model_name):
    if model_name == "MobileNetV2":
        return MobileNetV2(weights='imagenet'), (224, 224), mobilenet_preprocess
    elif model_name == "ResNet50":
        return ResNet50(weights='imagenet'), (224, 224), resnet_preprocess
    elif model_name == "ResNet50V2":
        return ResNet50V2(weights='imagenet'), (224, 224), resnet_preprocess
    elif model_name == "ResNet101":
        return ResNet101(weights='imagenet'), (224, 224), resnet_preprocess
    elif model_name == "ResNet101V2":
        return ResNet101V2(weights='imagenet'), (224, 224), resnet_preprocess
    elif model_name == "ResNet152":
        return ResNet152(weights='imagenet'), (224, 224), resnet_preprocess
    elif model_name == "ResNet152V2":
        return ResNet152V2(weights='imagenet'), (224, 224), resnet_preprocess
    elif model_name == "VGG16":
        return VGG16(weights='imagenet'), (224, 224), vgg_preprocess
    elif model_name == "InceptionV3":
        return InceptionV3(weights='imagenet'), (299, 299), inception_preprocess
    elif model_name == "EfficientNet":
        return EfficientNetB0(weights='imagenet'), (224, 224), efficientnet_preprocess
    elif model_name == "DenseNet121":
        return DenseNet121(weights='imagenet'), (224, 224), densenet_preprocess
    elif model_name == "Xception":
        return Xception(weights='imagenet'), (299, 299), xception_preprocess
    else:
        raise ValueError("Unsupported model name.")


def load_images_from_folder(folder_path, target_size, preprocess_func):
    images = []
    filenames = []
    for img_file in os.listdir(folder_path):
        img_path = os.path.join(folder_path, img_file)
        if img_file.lower().endswith(('png', 'jpg', 'jpeg')):
            img = image.load_img(img_path, target_size=target_size)
            img_array = image.img_to_array(img)
            img_array = np.expand_dims(img_array, axis=0)  # Add batch dimension here
            img_array = preprocess_func(img_array)  # Apply model-specific preprocessing
            images.append(img_array)
            filenames.append(img_file)
    return np.vstack(images), filenames  # Stack all images together for batch processing

# Universal Adversarial Perturbation (UAP) Attack
def universal_adversarial_perturbation(model, images, num_iterations=1000, epsilon=0.01):
    perturbation = tf.Variable(tf.zeros_like(images[0]), dtype=tf.float32)

    for _ in range(num_iterations):
        with tf.GradientTape() as tape:
            total_loss = 0
            for img in images:
                adversarial_image = tf.clip_by_value(img + perturbation, -1, 1)
                prediction = model(adversarial_image)
                loss = tf.keras.losses.categorical_crossentropy(
                    tf.one_hot(tf.argmax(prediction, axis=1).numpy()[0], 1000)[tf.newaxis, :], prediction
                )
                total_loss += loss
            total_loss /= len(images)

        gradients = tape.gradient(total_loss, perturbation)
        perturbation.assign_add(epsilon * tf.sign(gradients))  # Update perturbation
        perturbation.assign(tf.clip_by_value(perturbation, -epsilon, epsilon))  # Clip perturbation

    return perturbation

# Spatially Transformed Adversarial Attack
def spatial_transform_attack(model, image, epsilon=0.01, iterations=100):
    image = tf.Variable(image, dtype=tf.float32)
    original_label = tf.argmax(model(image), axis=1).numpy()[0]  # Extract scalar value
    perturbation = tf.zeros_like(image)  # Initialize perturbation

    for _ in range(iterations):
        with tf.GradientTape() as tape:
            tape.watch(image)
            adversarial_image = image + perturbation
            prediction = model(adversarial_image)
            loss = tf.keras.losses.categorical_crossentropy(
                tf.one_hot(original_label, 1000)[tf.newaxis, :], prediction
            )

        gradients = tape.gradient(loss, adversarial_image)
        perturbation += epsilon * tf.sign(gradients)  # Update perturbation
        perturbation = tf.clip_by_value(perturbation, -epsilon, epsilon)  # Clip perturbation

    adversarial_image = tf.clip_by_value(image + perturbation, -1, 1)
    return adversarial_image

# DeepFool Attack
def deepfool_attack(model, image, num_classes=10, max_iter=50, overshoot=0.02):
    image = tf.Variable(image, dtype=tf.float32)
    original_label = tf.argmax(model(image), axis=1).numpy()[0]  # Extract scalar value

    perturbed_image = tf.identity(image)

    for _ in range(max_iter):
        with tf.GradientTape() as tape:
            tape.watch(perturbed_image)
            logits = model(perturbed_image)
            original_class_score = logits[0, original_label]  # Use original_label as scalar

        gradients = tape.gradient(original_class_score, perturbed_image)
        grad_magnitude = tf.norm(gradients)

        if grad_magnitude == 0:
            break

        # Compute perturbation required to cross the decision boundary
        perturbation_step = (overshoot + 1) * gradients / grad_magnitude
        perturbed_image = perturbed_image + perturbation_step
        perturbed_image = tf.clip_by_value(perturbed_image, -1, 1)

        # Check if the perturbation causes misclassification
        new_label = tf.argmax(model(perturbed_image), axis=1).numpy()[0]  # Extract scalar value
        if new_label != original_label:
            print(f"Attack successful! Image misclassified as {new_label}")
            break

    return perturbed_image



# BIM attack function
def bim_attack(image, model, epsilon, alpha, iterations):
    adv_image = tf.identity(image)  # Copy the image to start with
    for i in range(iterations):
        with tf.GradientTape() as tape:
            tape.watch(adv_image)
            prediction = model(adv_image)
            loss = tf.keras.losses.categorical_crossentropy(
                tf.one_hot(np.argmax(prediction), 1000)[tf.newaxis, :], prediction
            )
        # Calculate gradients
        gradients = tape.gradient(loss, adv_image)
        # Update adversarial image by small steps (alpha) in the gradient direction
        adv_image = adv_image + alpha * tf.sign(gradients)
        # Clip to ensure perturbation does not exceed epsilon
        adv_image = tf.clip_by_value(adv_image, image - epsilon, image + epsilon)
        adv_image = tf.clip_by_value(adv_image, -1, 1)  # Ensure pixel values are valid
    return adv_image


# PGD attack function
def pgd_attack(image, model, epsilon, alpha, iterations):
    adv_image = tf.identity(image)  # Copy the image as a starting point
    for i in range(iterations):
        with tf.GradientTape() as tape:
            tape.watch(adv_image)
            prediction = model(adv_image)
            loss = tf.keras.losses.categorical_crossentropy(
                tf.one_hot(np.argmax(prediction), 1000)[tf.newaxis, :], prediction
            )
        # Calculate gradients
        gradients = tape.gradient(loss, adv_image)
        # Take a step in the direction of the gradient (alpha)
        adv_image = adv_image + alpha * tf.sign(gradients)
        # Project the image back into a valid range
        adv_image = tf.clip_by_value(adv_image, image - epsilon, image + epsilon)
        adv_image = tf.clip_by_value(adv_image, -1, 1)  # Ensure pixel values are within valid range
    return adv_image


# FGSM attack function
def fgsm_attack(image, model, epsilon):
    with tf.GradientTape() as tape:
        tape.watch(image)
        prediction = model(image)
        loss = tf.keras.losses.categorical_crossentropy(
            tf.one_hot(np.argmax(prediction), 1000)[tf.newaxis, :], prediction
        )

    gradients = tape.gradient(loss, image)
    signed_gradients = tf.sign(gradients)
    adversarial_image = image + epsilon * signed_gradients
    adversarial_image = tf.clip_by_value(adversarial_image, -1, 1)  # Ensure pixel values are in valid range
    return adversarial_image

# Untargeted Carlini & Wagner L2 Attack
def carlini_wagner_untargeted_attack(model, image, confidence=0, learning_rate=0.01, max_iter=1000, binary_search_steps=9, initial_const=0.01, clip_min=-1, clip_max=1):
    def loss_fn(modified_image, logits, const):
        # Misclassification loss (maximizing wrong class prediction)
        true_label = tf.one_hot(tf.argmax(model(image), axis=1), 1000)
        real = tf.reduce_sum(true_label * logits, axis=1)
        other = tf.reduce_max((1 - true_label) * logits - true_label * 10000, axis=1)
        loss1 = tf.maximum(real - other + confidence, 0)
        # L2 loss to minimize perturbation
        l2_loss = tf.reduce_sum(tf.square(modified_image - image))
        return const * loss1 + l2_loss

    batch_size = image.shape[0]
    modified_image = tf.Variable(image)

    optimizer = tf.keras.optimizers.Adam(learning_rate)

    best_l2 = np.inf
    best_adv_image = None

    for binary_step in range(binary_search_steps):
        # Iteratively optimize to minimize the loss
        for iteration in range(max_iter):
            with tf.GradientTape() as tape:
                tape.watch(modified_image)
                logits = model(modified_image)
                loss = loss_fn(modified_image, logits, initial_const)
            gradients = tape.gradient(loss, modified_image)
            optimizer.apply_gradients([(gradients, modified_image)])

            # Clip modified image within valid range
            modified_image.assign(tf.clip_by_value(modified_image, clip_min, clip_max))

            # Update the best adversarial example if it fools the classifier and minimizes L2 distance
            pred_label = tf.argmax(logits[0])
            true_label = tf.argmax(model(image)[0])
            l2_dist = tf.norm(modified_image - image)

            if pred_label != true_label and l2_dist < best_l2:
                best_l2 = l2_dist
                best_adv_image = modified_image.numpy()

    return best_adv_image if best_adv_image is not None else modified_image.numpy()

def attacks(att, original_image, model):
    if att == "UAP":
        uap = universal_adversarial_perturbation(model, [original_image])
        return uap

    elif att == "spatial_transform":
        adversarial_image = spatial_transform_attack(model, original_image)
        return adversarial_image

    elif att == "DeepFool":
        adversarial_image = deepfool_attack(model, original_image)
        return adversarial_image

    elif att == "BIM":
        epsilon = 0.03
        alpha = 0.01
        iterations = 10
        adversarial_image = bim_attack(original_image, model, epsilon, alpha, iterations)
        return adversarial_image

    elif att == "PGD":
        epsilon = 0.03
        alpha = 0.01
        iterations = 40
        adversarial_image = pgd_attack(original_image, model, epsilon, alpha, iterations)
        return adversarial_image

    elif att == "FGSM":
        epsilon = 0.01
        adversarial_image = fgsm_attack(original_image, model, epsilon)
        return adversarial_image

    elif att == "C_and_W":
        adversarial_image = carlini_wagner_untargeted_attack(model, original_image)
        return adversarial_image

    else:
        raise ValueError("Unsupported attack.")

def run_attack_on_dataset(att, images, model):
    adversarial_images = []
    for img in images:
        adversarial_image = attacks(att, tf.convert_to_tensor(np.expand_dims(img, axis=0)), model)
        adversarial_images.append(adversarial_image)
    return tf.concat(adversarial_images, axis=0)  # Concatenate the adversarial images into a batch

def compute_accuracy(model, original_images, adversarial_images):
    # Get predictions for original and adversarial images
    original_predictions = np.argmax(model.predict(original_images), axis=1)
    adversarial_predictions = np.argmax(model.predict(adversarial_images), axis=1)

    # Calculate accuracy
    accuracy_before_attack = accuracy_score(original_predictions, original_predictions)  # This will always be 100%
    accuracy_after_attack = accuracy_score(original_predictions, adversarial_predictions)

    print(f"Accuracy before attack: {accuracy_before_attack * 100}%")
    print(f"Accuracy after attack: {accuracy_after_attack * 100}%")

def display_images(original_image, adversarial_image):
    # Remove batch dimension and convert to numpy array for both original and adversarial images
    original_image_np = original_image[0].numpy()  # Original image
    adversarial_image_np = adversarial_image[0].numpy()  # Adversarial image

    # Reverse the preprocessing to get original pixel range (from -1,1 to [0,255] for visualization)
    original_image_np = (original_image_np + 1.0) * 127.5
    adversarial_image_np = (adversarial_image_np + 1.0) * 127.5

    # Plot images side by side
    plt.figure(figsize=(10, 5))

    # Original Image
    plt.subplot(1, 2, 1)
    plt.imshow(original_image_np.astype("uint8"))
    plt.title("Original Image")
    plt.axis("off")

    # Adversarial Image
    plt.subplot(1, 2, 2)
    plt.imshow(adversarial_image_np.astype("uint8"))
    plt.title("Adversarial Image")
    plt.axis("off")

    plt.show()

# Load the model and preprocessing function
model_name = input("Select a pretrained model (MobileNetV2, ResNet50, ResNet50V2, ResNet101, ResNet101V2, ResNet152, ResNet152V2, VGG16, InceptionV3, EfficientNet, DenseNet121, Xception, NASNetMobile, ShuffleNet, MobileNet, DenseNet169): ")
model, target_size, preprocess_func = load_model(model_name)

# Load images from folder
folder_path = input("Enter the folder path containing the images: ")
original_images, filenames = load_images_from_folder(folder_path, target_size, preprocess_func)

# Choose the attack type
att = input("Which attack do you want to perform? : (UAP ,spatial_transform ,DeepFool ,BIM ,PGD ,FGSM ,C_and_W): ")

# Run the attack on the dataset
adversarial_images = run_attack_on_dataset(att, original_images, model)

# Calculate and print accuracy before and after the attack
compute_accuracy(model, original_images, adversarial_images)

pip install gradio

import gradio as gr
import os

def process_images_and_attack(folder_path, model_name, attack_type):
    # Load model
    model, target_size, preprocess_func = load_model(model_name)

    # Load and preprocess images from the folder
    images, filenames = load_images_from_folder(folder_path, target_size, preprocess_func)

    # Get predictions for original images
    original_predictions = model.predict(images)
    original_classes = np.argmax(original_predictions, axis=1)

    # Perform adversarial attack
    adversarial_images = run_attack_on_dataset(attack_type, images, model)

    # Get predictions for adversarial images
    adversarial_predictions = model.predict(adversarial_images)
    adversarial_classes = np.argmax(adversarial_predictions, axis=1)

    # Calculate accuracy by comparing original and adversarial classes
    num_correct = np.sum(original_classes == adversarial_classes)
    accuracy = num_correct / len(original_classes) * 100

    # Prepare a result dictionary
    results = {
        'Filenames': filenames,
        'Original Class': original_classes.tolist(),
        'Adversarial Class': adversarial_classes.tolist(),
        'Accuracy': accuracy
    }
    return results


def gradio_interface():
    # Define the Gradio inputs and outputs
    folder_input = gr.inputs.Textbox(label="Folder Path (Upload Images Folder)")
    model_input = gr.inputs.Dropdown(choices=["MobileNetV2", "ResNet50", "VGG16", "InceptionV3", "EfficientNet", "DenseNet121", "Xception"], label="Select Model")
    attack_input = gr.inputs.Dropdown(choices=["UAP", "spatial_transform", "DeepFool", "BIM", "PGD", "FGSM", "C_and_W"], label="Select Attack")

    # Define output as a Gradio JSON output
    output = gr.outputs.JSON(label="Attack Results")

    # Launch Gradio Interface
    gr.Interface(fn=process_images_and_attack, inputs=[folder_input, model_input, attack_input], outputs=output, title="Adversarial Attack on Images", description="Upload a folder of images, select a model, and apply an adversarial attack.").launch()

if __name__ == "__main__":
    gradio_interface()